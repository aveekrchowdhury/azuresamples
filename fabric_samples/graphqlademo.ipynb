{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfceb95b",
   "metadata": {},
   "source": [
    "# 🚀 Microsoft Fabric GraphQL API Demo\n",
    "## Comprehensive Guide to Pagination, Filtering, and Querying\n",
    "\n",
    "This notebook demonstrates how to effectively use GraphQL with Microsoft Fabric's API, focusing on:\n",
    "\n",
    "- **🔄 Cursor-based Pagination** - Efficient data traversal using `first` and `after` parameters\n",
    "- **🔍 Advanced Filtering** - Complex filtering with `TripFilterInput`, `GeographyFilterInput`, etc.\n",
    "- **📊 Sorting & Ordering** - Using `TripOrderByInput` and other ordering inputs  \n",
    "- **📈 Aggregations** - Leveraging built-in aggregation functions\n",
    "- **🌐 Multi-entity Queries** - Working with Trips, Geography, Medallions, Weather, and more\n",
    "\n",
    "### 🗂️ Available Data Types:\n",
    "- **Trip** - Taxi trip records with pickup/dropoff details\n",
    "- **Geography** - Location data with zip codes and addresses\n",
    "- **Medallion** - Taxi medallion information\n",
    "- **Weather** - Weather data correlated with trips\n",
    "- **Time** - Time dimension tables\n",
    "- **vw_PaymentAnalysis** - Payment analysis views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ab34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Setup and Import Libraries\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(\"📋 Libraries loaded:\")\n",
    "print(\"   - requests: GraphQL HTTP client\")\n",
    "print(\"   - pandas: Data manipulation\")\n",
    "print(\"   - matplotlib/seaborn: Visualization\")\n",
    "print(\"   - azure.identity: Authentication\")\n",
    "print(\"   - json: JSON handling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔐 Authentication and GraphQL Client Setup\n",
    "\n",
    "# WARNING: This is for development/demo purposes only!\n",
    "# In production, use proper app registration with client_id and scopes\n",
    "print(\"🔑 Setting up authentication...\")\n",
    "\n",
    "app = InteractiveBrowserCredential()\n",
    "scope = 'https://analysis.windows.net/powerbi/api/user_impersonation'\n",
    "result = app.get_token(scope)\n",
    "\n",
    "if not result.token:\n",
    "    raise Exception(\"❌ Could not get access token\")\n",
    "\n",
    "# Configure GraphQL endpoint and headers\n",
    "endpoint = 'https://eebc13ddb5604280aeb3c6d342982b7e.zee.graphql.fabric.microsoft.com/v1/workspaces/eebc13dd-b560-4280-aeb3-c6d342982b7e/graphqlapis/d8b1987f-67b0-4934-bfff-662417bb3fc7/graphql'\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {result.token}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "print(\"✅ Authentication successful!\")\n",
    "print(\"🌐 GraphQL endpoint configured\")\n",
    "print(\"📡 Ready to execute queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cb69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛠️ GraphQL Helper Functions\n",
    "\n",
    "def execute_graphql_query(query, variables=None):\n",
    "    \"\"\"\n",
    "    Execute a GraphQL query with error handling and response parsing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        payload = {'query': query}\n",
    "        if variables:\n",
    "            payload['variables'] = variables\n",
    "            \n",
    "        response = requests.post(endpoint, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        if 'errors' in data:\n",
    "            print(f\"❌ GraphQL errors: {data['errors']}\")\n",
    "            return None\n",
    "            \n",
    "        return data['data']\n",
    "        \n",
    "    except Exception as error:\n",
    "        print(f\"❌ Query failed: {error}\")\n",
    "        return None\n",
    "\n",
    "def print_pagination_info(connection_data, entity_name=\"items\"):\n",
    "    \"\"\"\n",
    "    Print pagination information in a readable format\n",
    "    \"\"\"\n",
    "    if not connection_data:\n",
    "        return\n",
    "        \n",
    "    items_count = len(connection_data.get('items', []))\n",
    "    has_next = connection_data.get('hasNextPage', False)\n",
    "    end_cursor = connection_data.get('endCursor', 'None')\n",
    "    \n",
    "    print(f\"📊 Retrieved {items_count} {entity_name}\")\n",
    "    print(f\"📄 Has next page: {has_next}\")\n",
    "    print(f\"🔗 End cursor: {end_cursor}\")\n",
    "\n",
    "print(\"✅ Helper functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e5e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚕 Single Page Trip Data Query (Page Size: 10)\n",
    "\n",
    "def fetch_trips_page(page_size=10, after_cursor=None):\n",
    "    \"\"\"\n",
    "    Fetch a single page of trip data using cursor-based pagination\n",
    "    \"\"\"\n",
    "    # Build query arguments\n",
    "    args = f\"first: {page_size}\"\n",
    "    if after_cursor:\n",
    "        args += f', after: \"{after_cursor}\"'\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    query {{\n",
    "      trips({args}) {{\n",
    "         items {{\n",
    "            DateID\n",
    "            MedallionID\n",
    "            HackneyLicenseID\n",
    "            PickupTimeID\n",
    "            DropoffTimeID\n",
    "            PickupGeographyID\n",
    "            DropoffGeographyID\n",
    "            PickupLatitude\n",
    "            PickupLongitude\n",
    "            PickupLatLong\n",
    "            DropoffLatitude\n",
    "            DropoffLongitude\n",
    "            DropoffLatLong\n",
    "            PassengerCount\n",
    "            TripDurationSeconds\n",
    "            TripDistanceMiles\n",
    "            PaymentType\n",
    "            FareAmount\n",
    "            SurchargeAmount\n",
    "            TaxAmount\n",
    "            TipAmount\n",
    "            TollsAmount\n",
    "            TotalAmount\n",
    "         }}\n",
    "         endCursor\n",
    "         hasNextPage\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"🔄 Fetching trips page (size: {page_size})\")\n",
    "    if after_cursor:\n",
    "        print(f\"   Using cursor: {after_cursor[:20]}...\")\n",
    "    \n",
    "    data = execute_graphql_query(query)\n",
    "    \n",
    "    if data and 'trips' in data:\n",
    "        print_pagination_info(data['trips'], \"trips\")\n",
    "        return data['trips']\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Test: Fetch first page of trips\n",
    "print(\"=== SINGLE PAGE FETCH TEST ===\")\n",
    "first_page = fetch_trips_page(page_size=10)\n",
    "\n",
    "if first_page and first_page['items']:\n",
    "    print(f\"\\n📋 Sample trip data:\")\n",
    "    sample_trip = first_page['items'][0]\n",
    "    for key, value in sample_trip.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "else:\n",
    "    print(\"❌ No trip data retrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cba50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 Complete Pagination: Fetch ALL Trip Data\n",
    "\n",
    "def fetch_all_trips(page_size=10, max_pages=None, delay_seconds=0.5):\n",
    "    \"\"\"\n",
    "    Fetch ALL trip data using pagination with configurable limits\n",
    "    \n",
    "    Args:\n",
    "        page_size (int): Number of items per page\n",
    "        max_pages (int): Maximum pages to fetch (None for unlimited)\n",
    "        delay_seconds (float): Delay between requests to avoid rate limiting\n",
    "    \n",
    "    Returns:\n",
    "        list: All trip records retrieved\n",
    "    \"\"\"\n",
    "    all_trips = []\n",
    "    after_cursor = None\n",
    "    page_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"🚀 Starting complete trip data fetch\")\n",
    "    print(f\"📋 Configuration:\")\n",
    "    print(f\"   • Page size: {page_size}\")\n",
    "    print(f\"   • Max pages: {max_pages or 'Unlimited'}\")\n",
    "    print(f\"   • Delay between requests: {delay_seconds}s\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    while True:\n",
    "        page_count += 1\n",
    "        \n",
    "        # Check page limit\n",
    "        if max_pages and page_count > max_pages:\n",
    "            print(f\"🛑 Reached maximum page limit: {max_pages}\")\n",
    "            break\n",
    "        \n",
    "        print(f\"\\n📖 Fetching page {page_count}...\")\n",
    "        \n",
    "        # Fetch current page\n",
    "        page_data = fetch_trips_page(page_size=page_size, after_cursor=after_cursor)\n",
    "        \n",
    "        if not page_data or not page_data.get('items'):\n",
    "            print(f\"ℹ️  No more data found at page {page_count}\")\n",
    "            break\n",
    "        \n",
    "        # Add items to collection\n",
    "        items = page_data['items']\n",
    "        all_trips.extend(items)\n",
    "        \n",
    "        print(f\"   ✅ Added {len(items)} trips\")\n",
    "        print(f\"   📊 Total trips collected: {len(all_trips)}\")\n",
    "        \n",
    "        # Check if there's a next page\n",
    "        if not page_data.get('hasNextPage', False):\n",
    "            print(f\"ℹ️  Reached end of data (no more pages)\")\n",
    "            break\n",
    "        \n",
    "        # Update cursor for next page\n",
    "        after_cursor = page_data.get('endCursor')\n",
    "        \n",
    "        # Rate limiting delay\n",
    "        if delay_seconds > 0:\n",
    "            time.sleep(delay_seconds)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"🎯 PAGINATION COMPLETE!\")\n",
    "    print(f\"📊 Final Results:\")\n",
    "    print(f\"   • Total trips retrieved: {len(all_trips):,}\")\n",
    "    print(f\"   • Pages processed: {page_count}\")\n",
    "    print(f\"   • Time elapsed: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"   • Average time per page: {elapsed_time/page_count:.2f} seconds\")\n",
    "    \n",
    "    return all_trips\n",
    "\n",
    "# Execute complete pagination with reasonable limits for demo\n",
    "print(\"=== COMPLETE PAGINATION DEMO ===\")\n",
    "print(\"⚠️  Fetching first 5 pages for demonstration (50 trips max)\")\n",
    "print(\"    In production, remove max_pages limit to fetch all data\")\n",
    "\n",
    "all_trip_data = fetch_all_trips(\n",
    "    page_size=10,\n",
    "    max_pages=5,  # Limit for demo - remove this in production\n",
    "    delay_seconds=0.5  # Small delay to be respectful to the API\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bdab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Data Analysis and Summary\n",
    "\n",
    "if all_trip_data:\n",
    "    print(\"=== TRIP DATA ANALYSIS ===\")\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    df_trips = pd.DataFrame(all_trip_data)\n",
    "    \n",
    "    print(f\"📋 Dataset Overview:\")\n",
    "    print(f\"   • Total trips: {len(df_trips):,}\")\n",
    "    print(f\"   • Columns: {len(df_trips.columns)}\")\n",
    "    print(f\"   • Data types:\")\n",
    "    \n",
    "    # Show data types\n",
    "    for col in df_trips.columns:\n",
    "        dtype = df_trips[col].dtype\n",
    "        non_null = df_trips[col].notna().sum()\n",
    "        print(f\"     - {col}: {dtype} ({non_null}/{len(df_trips)} non-null)\")\n",
    "    \n",
    "    print(f\"\\n💰 Financial Summary:\")\n",
    "    if 'FareAmount' in df_trips.columns:\n",
    "        fare_amounts = pd.to_numeric(df_trips['FareAmount'], errors='coerce')\n",
    "        total_amounts = pd.to_numeric(df_trips['TotalAmount'], errors='coerce')\n",
    "        \n",
    "        print(f\"   • Total Fare Amount: ${fare_amounts.sum():,.2f}\")\n",
    "        print(f\"   • Average Fare: ${fare_amounts.mean():.2f}\")\n",
    "        print(f\"   • Total Amount (with tips/taxes): ${total_amounts.sum():,.2f}\")\n",
    "        print(f\"   • Average Total: ${total_amounts.mean():.2f}\")\n",
    "    \n",
    "    print(f\"\\n🚗 Trip Summary:\")\n",
    "    if 'PassengerCount' in df_trips.columns:\n",
    "        passenger_counts = pd.to_numeric(df_trips['PassengerCount'], errors='coerce')\n",
    "        print(f\"   • Total Passengers: {passenger_counts.sum():,}\")\n",
    "        print(f\"   • Average Passengers per Trip: {passenger_counts.mean():.1f}\")\n",
    "    \n",
    "    if 'TripDistanceMiles' in df_trips.columns:\n",
    "        distances = pd.to_numeric(df_trips['TripDistanceMiles'], errors='coerce')\n",
    "        print(f\"   • Total Distance: {distances.sum():,.1f} miles\")\n",
    "        print(f\"   • Average Distance: {distances.mean():.1f} miles\")\n",
    "    \n",
    "    print(f\"\\n💳 Payment Type Distribution:\")\n",
    "    if 'PaymentType' in df_trips.columns:\n",
    "        payment_counts = df_trips['PaymentType'].value_counts()\n",
    "        for payment_type, count in payment_counts.items():\n",
    "            percentage = (count / len(df_trips)) * 100\n",
    "            print(f\"   • {payment_type}: {count} trips ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n📋 Sample Records (first 3 trips):\")\n",
    "    print(df_trips.head(3).to_string(index=False))\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No trip data available for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 Trip Data Visualization\n",
    "\n",
    "if all_trip_data and len(all_trip_data) > 0:\n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Trip Data Analysis Dashboard', fontsize=16, y=1.02)\n",
    "    \n",
    "    # 1. Fare Amount Distribution\n",
    "    if 'FareAmount' in df_trips.columns:\n",
    "        fare_amounts = pd.to_numeric(df_trips['FareAmount'], errors='coerce').dropna()\n",
    "        if len(fare_amounts) > 0:\n",
    "            axes[0, 0].hist(fare_amounts, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "            axes[0, 0].set_title('Fare Amount Distribution')\n",
    "            axes[0, 0].set_xlabel('Fare Amount ($)')\n",
    "            axes[0, 0].set_ylabel('Frequency')\n",
    "            axes[0, 0].axvline(fare_amounts.mean(), color='red', linestyle='--', \n",
    "                              label=f'Mean: ${fare_amounts.mean():.2f}')\n",
    "            axes[0, 0].legend()\n",
    "    \n",
    "    # 2. Payment Type Distribution\n",
    "    if 'PaymentType' in df_trips.columns:\n",
    "        payment_counts = df_trips['PaymentType'].value_counts()\n",
    "        if len(payment_counts) > 0:\n",
    "            axes[0, 1].pie(payment_counts.values, labels=payment_counts.index, autopct='%1.1f%%')\n",
    "            axes[0, 1].set_title('Payment Type Distribution')\n",
    "    \n",
    "    # 3. Trip Distance Distribution\n",
    "    if 'TripDistanceMiles' in df_trips.columns:\n",
    "        distances = pd.to_numeric(df_trips['TripDistanceMiles'], errors='coerce').dropna()\n",
    "        if len(distances) > 0:\n",
    "            axes[1, 0].hist(distances, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "            axes[1, 0].set_title('Trip Distance Distribution')\n",
    "            axes[1, 0].set_xlabel('Distance (miles)')\n",
    "            axes[1, 0].set_ylabel('Frequency')\n",
    "            axes[1, 0].axvline(distances.mean(), color='red', linestyle='--', \n",
    "                              label=f'Mean: {distances.mean():.2f} miles')\n",
    "            axes[1, 0].legend()\n",
    "    \n",
    "    # 4. Passenger Count Distribution\n",
    "    if 'PassengerCount' in df_trips.columns:\n",
    "        passenger_counts = df_trips['PassengerCount'].value_counts().sort_index()\n",
    "        if len(passenger_counts) > 0:\n",
    "            axes[1, 1].bar(passenger_counts.index, passenger_counts.values, \n",
    "                          alpha=0.7, color='orange', edgecolor='black')\n",
    "            axes[1, 1].set_title('Passenger Count Distribution')\n",
    "            axes[1, 1].set_xlabel('Number of Passengers')\n",
    "            axes[1, 1].set_ylabel('Number of Trips')\n",
    "            axes[1, 1].set_xticks(passenger_counts.index)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create correlation matrix if we have numeric columns\n",
    "    numeric_cols = df_trips.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 1:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        correlation_matrix = df_trips[numeric_cols].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                   square=True, linewidths=0.5)\n",
    "        plt.title('Trip Data Correlation Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2bb7e1",
   "metadata": {},
   "source": [
    "## 🚀 Advanced Pagination Techniques\n",
    "\n",
    "### Handling Large Datasets\n",
    "\n",
    "When working with large datasets through GraphQL pagination, consider these best practices:\n",
    "\n",
    "1. **Rate Limiting**: Add delays between requests to avoid overwhelming the API\n",
    "2. **Error Handling**: Implement robust retry logic for network failures\n",
    "3. **Memory Management**: Process data in chunks to avoid memory issues\n",
    "4. **Progress Tracking**: Show progress for long-running operations\n",
    "5. **Caching**: Store intermediate results to resume interrupted operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af52edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Production-Ready Pagination with Error Handling\n",
    "\n",
    "import time\n",
    "import logging\n",
    "from typing import List, Dict, Optional, Generator\n",
    "\n",
    "def fetch_all_trips_robust(\n",
    "    page_size: int = 10,\n",
    "    max_total_records: Optional[int] = None,\n",
    "    delay_between_requests: float = 0.5,\n",
    "    max_retries: int = 3\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Robust pagination implementation with error handling and rate limiting.\n",
    "    \n",
    "    Args:\n",
    "        page_size: Number of records per page\n",
    "        max_total_records: Maximum total records to fetch (None = all)\n",
    "        delay_between_requests: Seconds to wait between API calls\n",
    "        max_retries: Maximum retry attempts for failed requests\n",
    "    \n",
    "    Returns:\n",
    "        List of all trip records\n",
    "    \"\"\"\n",
    "    all_trips = []\n",
    "    cursor = None\n",
    "    page_number = 1\n",
    "    total_fetched = 0\n",
    "    \n",
    "    print(f\"🚀 Starting robust pagination (page_size={page_size}, max_records={max_total_records})\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    while True:\n",
    "        retry_count = 0\n",
    "        current_page_data = None\n",
    "        \n",
    "        # Retry logic for current page\n",
    "        while retry_count <= max_retries:\n",
    "            try:\n",
    "                print(f\"📄 Fetching page {page_number} (attempt {retry_count + 1}/{max_retries + 1})\")\n",
    "                \n",
    "                current_page_data = fetch_trips_page(\n",
    "                    page_size=page_size, \n",
    "                    cursor=cursor\n",
    "                )\n",
    "                \n",
    "                break  # Success, exit retry loop\n",
    "                \n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                print(f\"⚠️ Error on page {page_number}, attempt {retry_count}: {str(e)}\")\n",
    "                \n",
    "                if retry_count <= max_retries:\n",
    "                    wait_time = 2 ** retry_count  # Exponential backoff\n",
    "                    print(f\"⏳ Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"❌ Failed to fetch page {page_number} after {max_retries + 1} attempts\")\n",
    "                    print(f\"📊 Returning {len(all_trips)} trips fetched so far\")\n",
    "                    return all_trips\n",
    "        \n",
    "        # Process successful page\n",
    "        if current_page_data and current_page_data.get('items'):\n",
    "            trips_on_page = current_page_data['items']\n",
    "            all_trips.extend(trips_on_page)\n",
    "            total_fetched += len(trips_on_page)\n",
    "            \n",
    "            print(f\"✅ Page {page_number}: {len(trips_on_page)} trips fetched\")\n",
    "            print(f\"📊 Total so far: {total_fetched} trips\")\n",
    "            \n",
    "            # Check if we've reached the maximum limit\n",
    "            if max_total_records and total_fetched >= max_total_records:\n",
    "                all_trips = all_trips[:max_total_records]  # Trim to exact limit\n",
    "                print(f\"🏁 Reached maximum limit of {max_total_records} records\")\n",
    "                break\n",
    "            \n",
    "            # Check if there are more pages\n",
    "            if not current_page_data.get('hasNextPage', False):\n",
    "                print(f\"🏁 No more pages available\")\n",
    "                break\n",
    "            \n",
    "            # Prepare for next page\n",
    "            cursor = current_page_data.get('endCursor')\n",
    "            if not cursor:\n",
    "                print(f\"⚠️ No cursor for next page, stopping\")\n",
    "                break\n",
    "            \n",
    "            page_number += 1\n",
    "            \n",
    "            # Rate limiting\n",
    "            if delay_between_requests > 0:\n",
    "                print(f\"⏱️ Waiting {delay_between_requests}s before next request...\")\n",
    "                time.sleep(delay_between_requests)\n",
    "        else:\n",
    "            print(f\"❌ No data returned for page {page_number}\")\n",
    "            break\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"🎉 Pagination complete! Total trips fetched: {len(all_trips)}\")\n",
    "    return all_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5766da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧪 Test the Robust Pagination (Limited to 50 records for demo)\n",
    "\n",
    "print(\"🧪 TESTING ROBUST PAGINATION\")\n",
    "print(\"This demo fetches 50 records to show the robust pagination in action...\")\n",
    "print()\n",
    "\n",
    "# Test with limited records for demonstration\n",
    "test_trips = fetch_all_trips_robust(\n",
    "    page_size=10,\n",
    "    max_total_records=50,  # Limit for demo\n",
    "    delay_between_requests=0.1,  # Minimal delay for demo\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "if test_trips:\n",
    "    print(f\"\\n🎯 RESULTS SUMMARY:\")\n",
    "    print(f\"   ✅ Successfully fetched {len(test_trips)} trip records\")\n",
    "    print(f\"   📄 Pages processed: {(len(test_trips) - 1) // 10 + 1}\")\n",
    "    print(f\"   🔍 Sample trip IDs: {[trip.get('TripId', 'N/A') for trip in test_trips[:5]]}\")\n",
    "else:\n",
    "    print(\"\\n❌ No trips were fetched\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b4ab4",
   "metadata": {},
   "source": [
    "## 📚 Summary & Next Steps\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "✅ **Authentication Setup**: Configured Microsoft Fabric GraphQL API access  \n",
    "✅ **Schema Understanding**: Analyzed the Trip data structure with pagination support  \n",
    "✅ **Basic Pagination**: Implemented simple page-by-page data fetching  \n",
    "✅ **Complete Pagination**: Created functions to fetch ALL data using cursor-based pagination  \n",
    "✅ **Data Analysis**: Added comprehensive data analysis and visualization  \n",
    "✅ **Production-Ready Code**: Implemented robust error handling and rate limiting  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Page Size**: Use `first: 10` parameter to control page size\n",
    "2. **Cursor Navigation**: Use `after: \"cursor_value\"` for next pages\n",
    "3. **Completion Detection**: Check `hasNextPage` to know when to stop\n",
    "4. **Error Handling**: Always implement retry logic for production systems\n",
    "5. **Rate Limiting**: Add delays between requests to be API-friendly\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Scale Up**: Remove the `max_total_records` limit to fetch complete dataset\n",
    "- **Data Pipeline**: Export results to CSV/database for further analysis\n",
    "- **Monitoring**: Add logging and metrics for production deployments\n",
    "- **Optimization**: Implement parallel processing for multiple data streams\n",
    "\n",
    "### 🎯 Ready to Use!\n",
    "\n",
    "Your pagination implementation is now ready to handle real-world scenarios with:\n",
    "- Configurable page sizes\n",
    "- Robust error handling  \n",
    "- Progress tracking\n",
    "- Memory-efficient processing\n",
    "- Production-grade reliability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
